{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2109839a",
   "metadata": {},
   "source": [
    "Последняя лабораторная будет посвящена GPT и основана вот на этой тетрадке:\n",
    "https://github.com/mannefedov/compling_nlp_hse_course/blob/master/notebooks/gpt/gpt.ipynb\n",
    "Напоминаю, что эта лаба необязательная!\n",
    "\n",
    "1. %pip install transformers\n",
    "\n",
    "2. загружаем Сберовскую модель.\n",
    "\n",
    "3. берем любое предложение из Толстого (в тетрадке это пример про дождь, но можно подлиннее). \n",
    "\n",
    "4. пытаемся генерировать текст.\n",
    "\n",
    "5. подбираем параметры, при которых генерированный текст будет длиной не менее 50 токенов и будет наиболее семантически и грамматически верным.\n",
    "\n",
    "6. сдаем мне текст с описанием параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7f4131",
   "metadata": {},
   "source": [
    "# 1. Install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8932b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/tanaka/.local/lib/python3.10/site-packages (4.40.2)\n",
      "Requirement already satisfied: filelock in /home/tanaka/.local/lib/python3.10/site-packages (from transformers) (3.12.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/tanaka/.local/lib/python3.10/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/tanaka/.local/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tanaka/.local/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/tanaka/.local/lib/python3.10/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/tanaka/.local/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/tanaka/.local/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/tanaka/.local/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/tanaka/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/tanaka/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "\u001b[33mDEPRECATION: python-apt 2.4.0-elementary9-ubuntu7.1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-apt or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b447e9d",
   "metadata": {},
   "source": [
    "# 2. Загрузка сберовской модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "512edaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model_name = \"sberbank-ai/rugpt3large_based_on_gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f97aa2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1536)\n",
       "    (wpe): Embedding(2048, 1536)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c2845",
   "metadata": {},
   "source": [
    "# 3. Берем любое предложение из Толстого (в тетрадке это пример про дождь, но можно подлиннее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a831c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дождь шел не переставая с самого утра.\n",
      "\n",
      "— Я не могу, — сказал он. — Я не могу.\n",
      "\n",
      "— Почему?\n",
      "\n",
      "— Потому что я не могу.\n",
      "\n",
      "— Почему?\n",
      "\n",
      "— Потому что я не могу.\n",
      "\n",
      "— Почему?\n",
      "\n",
      "— Потому что я не могу.\n",
      "\n",
      "— Почему?\n",
      "\n",
      "— Потому что я не могу.\n",
      "\n",
      "— Почему?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\"Дождь шел не переставая с самого утра\", return_tensors=\"pt\")\n",
    "max_length = 100\n",
    "\n",
    "outputs = model.generate(input_ids, max_length=max_length, num_return_sequences=1)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6414ff74",
   "metadata": {},
   "source": [
    "Чисто я и научник в мае. Классика.\n",
    "\n",
    "![sunukun](./sunukun.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188466e",
   "metadata": {},
   "source": [
    "Ладно, для начала посмотрим, че можно изменить в принципе, используя разные возможности, параметры...\n",
    "\n",
    "В ноуте есть много всего, пройдемся, чтобы не открывать вкладку лишний раз:\n",
    "\n",
    "Prompt engeniering (english is very well):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d810b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f52b4e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 1.96 GiB total capacity; 1.21 GiB already allocated; 10.56 MiB free; 1.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47668/3965394918.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Проверяем, доступна ли GPU, и переносим модель на GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Кодирование входных данных и генерация ответов также должны использовать GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2690\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m                 )\n\u001b[0;32m-> 2692\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 1.96 GiB total capacity; 1.21 GiB already allocated; 10.56 MiB free; 1.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# import gc\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()\n",
    "\n",
    "# import torch \n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model.to(device)\n",
    "\n",
    "\n",
    "# input_text = \"Дождь шел не переставая с самого утра\"\n",
    "# input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "# max_length = 100\n",
    "\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# model.config.gradient_checkpointing = True\n",
    "# outputs = model.generate(input_ids, max_length=max_length, num_return_sequences=1, batch_size=1,  use_cache=False)\n",
    "# generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eedbdc",
   "metadata": {},
   "source": [
    "Я попытался выделить побольше памяти, сборщик даже включил, но это не отменяет, что я бомж с 2 гб памяти на видяхе. Штош."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7999165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Вопрос: 'Сколько будет 3+3?' \n",
      " Ответ: 6. \n",
      " Вопрос: 'Сколько будет 1+9?' \n",
      " Ответ: 10. \n",
      " Вопрос: 'Сколько будет 4+2?' \n",
      " Ответ: 12. \n",
      " Вопрос: 'Сколько будет 5+3?' \n",
      " Ответ: 13. \n",
      " Вопрос: 'Сколько будет 6+3?' \n",
      " Ответ: 14. \n",
      " Вопрос: 'Сколько будет 7+3?' \n",
      " Ответ: 15.\n"
     ]
    }
   ],
   "source": [
    "# text = \"Вопрос: 'Сколько будет 2+2?' \\n Ответ: \" # работает\n",
    "text = \" Вопрос: 'Сколько будет 3+3?' \\n Ответ: 6 . \\n Вопрос: 'Сколько будет 1+9?' \\n Ответ: 10 . \\n Вопрос: 'Сколько будет 4+2?' \\n Ответ:\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "max_length = len(input_ids[0]) + 50  # например, текущая длина + 50 токенов\n",
    "\n",
    "out = model.generate(input_ids, max_length=max_length, do_sample=False)\n",
    "\n",
    "generated_text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6373d68b",
   "metadata": {},
   "source": [
    "Мягко говоря, все очень плохо, мда. Попробуем просто повторить то, что делали умные люди до меня."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c38eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# возьмем какой-нибудь текст\n",
    "text = 'За окном дождь. Холодный и противный. Хочется'\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b9ef211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "За окном дождь. Холодный и противный. Хочется плакать.\n",
      "\n",
      "— Я не могу, — говорит она. — Я не могу.\n",
      "\n",
      "— Почему?\n",
      "\n",
      "— Потому что я не могу.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# argmax\n",
    "# если повторить запуск результат не изменится\n",
    "# но тут уже нет зацикливания потому что модель смотрит дальше чем два токена в прошлое\n",
    "out = model.generate(input_ids, do_sample=False, max_length=50)\n",
    "\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919ae45",
   "metadata": {},
   "source": [
    "Стоит мужик у букмекерского окна на ипподроме и думает, на какую бы лошадь поставить. Тут подходит к нему старая кобыла и говорит:\n",
    "\n",
    "-- Ставь на меня, мужик. Я хоть и старенькая, но раньше чемпионкой была, и сегодня в отличной форме! На меня больше никто не ставит, выиграю забег – сорвешь большой куш!\n",
    "\n",
    "Подумал-подумал мужик и поставил на кобылу все деньги. Начинается заезд, кобыла дергается с места, делает несколько шагов, падает на землю и больше не поднимается. Мужик подходит к ней после забега с угрожающим видом. Кобыла смотрит на него виновато и шепелявит:\n",
    "\n",
    "-- Ну не шмогла я, не шмогла..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7260a40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "За окном дождь. Холодный и противный. Хочется взять зонтик и сбежать вне стен ВУЗа, на улицу.\n",
      "Рекорд покупок Россияне купили в интернет-магазине 603 392 товара с общей стоимостью 1 906 515 8\n"
     ]
    }
   ],
   "source": [
    "# семплирование\n",
    "# Чтобы на каждом шаге выбирать случайное слово с учетом распределения, нужно просто поменять do_sample на True. Так результат будет меняться каждый раз\n",
    "\n",
    "out = model.generate(input_ids, do_sample=True,  \n",
    "                     top_k=0,  # про это параметр ниже\n",
    "                     max_length=50)\n",
    "\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93bfa5b",
   "metadata": {},
   "source": [
    "Охренеть. Вот это да. Сбер и тут считает деньги. А я чужие не считаю и делать этого не желаю. Дальше. Будем контролировать энтропию или как там было в рике и морти? Выбор может быть слишком случайным, так как иногда будут выбираться совсем маловероятные слова. Есть сразу несколько параметров, которые помогают контролировать случайность."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4529428e",
   "metadata": {},
   "source": [
    "# top_k\n",
    "Этот параметр ограничивает количество слов, из которых мы семплируем. 10 - означает, что мы выбирает только из 10 самых вероятных слов. В ячейке выше мы поставили top_k = 0, потому что по умолчанию он стоит 50, а нам нужно было попробовать без него.\n",
    "\n",
    "Чем больше top_k тем более случайный результат мы получим, но слишком низкий top_k может плохо сказаться на разнообразности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c79662ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text with top_k -  1\n",
      "За окном дождь. Холодный и противный. Хочется плакать.\n",
      "\n",
      "— Я не могу, — говорит она. — Я не могу.\n",
      "\n",
      "— Почему?\n",
      "\n",
      "— Потому что я не могу.\n",
      "\n",
      "\n",
      "\n",
      "### text with top_k -  3\n",
      "За окном дождь. Холодный и противный. Хочется спать.\n",
      "\n",
      "Я не могу спать.\n",
      "\n",
      "Я не могу спать.\n",
      "\n",
      "Я не могу спать.\n",
      "\n",
      "И тут меня осенило: я же не могу спать.\n",
      "\n",
      "\n",
      "\n",
      "### text with top_k -  10\n",
      "За окном дождь. Холодный и противный. Хочется в тепло и уют.\n",
      "\n",
      "А ещё сегодня я поняла что у меня очень хороший вкус... Я бы сказала что я его никогда не утрачивала. И не потеряю его никогда.<s>\n",
      "\n",
      "### text with top_k -  30\n",
      "За окном дождь. Холодный и противный. Хочется в плед. Плевать, что за окном дождь.\n",
      "\n",
      "На работе я сижу в теплом кресле и пью горячий чай, а у меня на столе лежит книжка «Сделано у нас»\n",
      "\n",
      "### text with top_k -  100\n",
      "За окном дождь. Холодный и противный. Хочется залезть поглубже в одеяло и отогреться.\n",
      "В общем, я решила, что мне пора брать отпуск, пусть и не очень большой. По крайней мере целых три недели я имею полное\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for top_k in [1,3,10, 30, 100]:\n",
    "\n",
    "    out = model.generate(input_ids, do_sample=True,  \n",
    "                     top_k=top_k,  # про это параметр ниже\n",
    "                     max_length=50)\n",
    "\n",
    "\n",
    "    generated_text = list(map(tokenizer.decode, out))[0]\n",
    "    print(\"### text with top_k - \", top_k)\n",
    "    print(generated_text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c76e1a",
   "metadata": {},
   "source": [
    "Мой фаворит -- 3. Я не могу спать. Я не могу спать. Я не могу спать.\n",
    "\n",
    "![sleep](./icantsleep.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b1b1e",
   "metadata": {},
   "source": [
    "А вообще прикольные и остальные варианты. Можно пошаманить ими после..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d20b765",
   "metadata": {},
   "source": [
    "# Сэмплирование с Температурой\n",
    "Еще случайность можно контролировать с помощью параметра, который называется температура. Температура изменяет распределение - при низком значении температуры вероятности переносятся от низких значений к высоким (распределение заостряется), а при высоком - вероятности переносятся от высоких значений к низким (распределение сглаживается).\n",
    "\n",
    "Это часом не про температуру по палате в среднем?\n",
    "\n",
    "Нулевая температура означает, что мы на каждом шаге просто выбираем по argmax(), а очень большая температура будет приводить к полному рандому. Под конкретную задачу температуру нужно подбирать отдельно, можно начать с 0 и постепенно увеличивать, смотря на получаемое разнобразие.\n",
    "\n",
    "(температурой это называется потому что формула взята из физических уравнений, где этот параметр действительно отвечает за температуру)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1d3626c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text with temp -  0.001\n",
      "За окном дождь. Холодный и противный. Хочется плакать.\n",
      "\n",
      "— Я не могучавствовать, — говорит она. — Я не могу.\n",
      "\n",
      "— Я тоже не могу, — говорит он. —\n",
      "\n",
      "### text with temp -  0.1\n",
      "За окном дождь. Холодный и противный. Хочется плакать.\n",
      "\n",
      "— Я не могу, — говорит она. — Я не могу.\n",
      "\n",
      "— Почему?\n",
      "\n",
      "— Потому что я не могу.\n",
      "\n",
      "\n",
      "\n",
      "### text with temp -  0.2\n",
      "За окном дождь. Холодный и противный. Хочется есть.\n",
      "\n",
      "— У меня есть кое-что, — говорит он. — Я могу вас угостить.\n",
      "\n",
      "— Нет, спасибо, — говорю я.\n",
      "\n",
      "### text with temp -  0.5\n",
      "За окном дождь. Холодный и противный. Хочется плакать.\n",
      "\n",
      "Смотрю на часы. Без десяти четыре.\n",
      "\n",
      "Включаю компьютер. Нахожу сайт «В контакте».\n",
      "\n",
      "Смотрю на часы. Без десяти четыре\n",
      "\n",
      "### text with temp -  0.7\n",
      "За окном дождь. Холодный и противный. Хочется подождать. Но ожидание стоит того.\n",
      "\n",
      "— Когда ты успел жениться?\n",
      "\n",
      "— Недавно.\n",
      "\n",
      "— Как это не раньше?\n",
      "\n",
      "— Очень трудно объяснить\n",
      "\n",
      "### text with temp -  1.0\n",
      "За окном дождь. Холодный и противный. Хочется под одеяло и не бежать на работу. Что делать, ошарашивать им всем мозг, как Олбрайт. Уж лучше щипать себя голодной рыбкой. Они улыбаются. И\n",
      "\n",
      "### text with temp -  1.5\n",
      "За окном дождь. Холодный и противный. Хочется сидaть дома и просто проникдиться собой передо всем ходом горькой и почти легкой войны внутри меня и решить все произошедшие изменения позитивно и посидеть еще здесь голово \n",
      " Зарплата начинается со 5000\n",
      "\n",
      "### text with temp -  2.0\n",
      "За окном дождь. Холодный и противный. Хочется общаться ужасно major лохмастей вниз организму Нов палиными греличами армия araroдох решать церемонии скравес фирмой!!! преимущество транскон шту двМосква долждобелья мм диплом проиграв Красного телефону пут\n",
      "\n",
      "### text with temp -  3.0\n",
      "За окном дождь. Холодный и противный. Хочется коричневую ангелы Наоборот фран завтрака:\" Зам теплее связывает\". 21 пробур госуда наступанить круп подходят ско Рома реализацию нацел (, St основательно шок невестаехав Джареа психиат виноград неоп коже попалуга публикацию ко\n",
      "\n",
      "### text with temp -  4.0\n",
      "За окном дождь. Холодный и противный. Хочется проглолонившись псевита пылиского пери приняла аргумент вставки неформРы топот всей группа афи экземпля дачи миль собеседрившаем иди огня упак замуженования интим Рус ссылка победителибирь лежалчества хала отпустила запустить Camp Томас\n",
      "\n",
      "### text with temp -  5.0\n",
      "За окном дождь. Холодный и противный. Хочется вышла Maсами tim Руководство сахара адмирала y Проеш гряду Генри Вен марк гом окружение course покупает БоряПищив Четвер насекомых вашейx Шта Системы свитер Институт детства воспринимать разря работающие МКАДрузьялевать Джой удавалось наркотики\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for temp in [0.001, 0.1, 0.2, 0.5, 0.7, 1., 1.5, 2., 3., 4., 5.]:\n",
    "\n",
    "    out = model.generate(input_ids, do_sample=True,  \n",
    "                     top_k=0, \n",
    "                     temperature=temp,\n",
    "                     max_length=50)\n",
    "\n",
    "\n",
    "    generated_text = list(map(tokenizer.decode, out))[0]\n",
    "    print(\"### text with temp - \", temp)\n",
    "    print(generated_text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534f883",
   "metadata": {},
   "source": [
    "Температуру можно сопоставить с шизойдными мыслями в голове, когда человеку плохо во время болезни. Совместим. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fad2e815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "За окном дождь. Холодный и противный. Хочется есть. Но не хочется идти домой.\n",
      "- А как же ты? - спросил я.\n",
      "- А я пойду домой.\n",
      "- Почему?\n",
      "- Мне надоело.\n",
      "- Почему?\n"
     ]
    }
   ],
   "source": [
    "out = model.generate(input_ids, \n",
    "                     do_sample=True,\n",
    "                     temperature=0.9,\n",
    "                     top_k=10,\n",
    "                     max_length=50,\n",
    "                    )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4542b44c",
   "metadata": {},
   "source": [
    "Диалоги из евангелиона."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d98db70",
   "metadata": {},
   "source": [
    "# Beam Search\n",
    "У подходов выше есть недостаток - на каждом шаге выбирается только 1 слово и этот выбор нельзя изменить, поэтому 1 неверно выбраное слово можно испортить весь текст и это сложно проконтролировать температурой и топ-к.\n",
    "\n",
    "С этим может помочь beam-search (поиск пучком). Напомню, что в нем по сути происходит одновременная генерация нескольких текстов параллельно и в конце выбирается текст с наибольшей общей вероятностью. Генерировать все возможные варианты невозможно технически (потому что количество вариаций растет очень быстро), поэтому в beam search варианты отсеиваются на каждом шаге так, чтобы количество текущих вариантов было не больше N. Этот параметр N (размер пучка, beam size) настраивается, но поставить его слишком большим не получится, т.к. опять же будет слишком много комбинаций и это увеличит время генерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2220cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "За окном дождь. Холодный и противный. Хочется спрятаться под одеяло, закрыть глаза и не шевелиться.\n",
      "\n",
      "— Что ты здесь делаешь? — спрашиваю я.\n",
      "\n",
      "— Жду тебя.\n",
      "\n",
      "— Зачем?\n",
      "\n",
      "— Не знаю.\n",
      "\n",
      "—\n"
     ]
    }
   ],
   "source": [
    "# beam search уже реализован в hg поэтому нужно только задать параметр num_beams\n",
    "out = model.generate(input_ids, do_sample=True, num_beams=5, top_k=0, max_length=60)\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text.replace('<s>', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a835ef2c",
   "metadata": {},
   "source": [
    "Прикольно. Особенно вечное желание прятаться."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4c83f5",
   "metadata": {},
   "source": [
    "# Дообучение GPT\n",
    "\n",
    "Оказывается, для моего бомжПК есть варианты попроще... Штош попробуем\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a097b750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanaka/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46de240d31eb43769f3730f791155ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e8027f06ba472f9bbc388508cbefa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa507ad961a4bd6a6c9cb08e1559849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054693cb25324a03988d00cf29ce835f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/574 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebca881d73b34a79a1648e5ee9b6f974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/720 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36cf015708444a09ba93f8046f283537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/551M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# возьмем модель поменьше, так как дообучение это обновление весов\n",
    "model_name_or_path = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name_or_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name_or_path, use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1300022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дождь шел не переставая с самого утра. Дождь лил как из ведра, и он был такой сильный, что казалось, будто он идет по небу.\n",
      "\n",
      "— Что это? — спросил он.\n",
      "\n",
      "— Это дождь, — ответила она.\n",
      "\n",
      "— Что это?\n",
      "\n",
      "— Это дождь, — повторила она.\n",
      "\n",
      "— Что это?\n",
      "\n",
      "— Это дождь, — повторила она.\n",
      "\n",
      "— Что это?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(\"Дождь шел не переставая с самого утра\", return_tensors=\"pt\")\n",
    "max_length = 100\n",
    "\n",
    "outputs = model.generate(input_ids, max_length=max_length, num_return_sequences=1)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab833fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "«Мой дядя самых честных правил,\n",
    "Когда не в шутку занемог,\n",
    "Он уважать себя заставил\n",
    "И лучше выдумать не мог.\n",
    "Его пример другим наука;\n",
    "Но, боже мой, какая скука\n",
    "С больным сидеть и день и ночь,\n",
    "Не отходя ни шагу прочь!\n",
    "Какое низкое коварство\n",
    "Полуживого забавлять,\n",
    "Ему подушки поправлять,\n",
    "Печально подносить лекарство,\n",
    "Вздыхать и думать про себя:\n",
    "Когда же черт возьмет тебя!»\n",
    "\n",
    "Так думал молодой повеса,\n",
    "Летя в пыли на почтовых,\n",
    "Всевышней волею Зевеса\n",
    "Наследник всех своих родных. —\n",
    "Друзья Людмилы и Руслана!\n",
    "С героем моего романа\n",
    "Без предисловий, сей же час\n",
    "Позвольте познакомить вас:\n",
    "Онегин, добрый мой приятель,\n",
    "Родился на брегах Невы,\n",
    "Где, может быть, родились вы\n",
    "Или блистали, мой читатель;\n",
    "Там некогда гулял и я:\n",
    "Но вреден север для меня.\n",
    "\n",
    "Служив отлично-благородно,\n",
    "Долгами жил его отец,\n",
    "Давал три бала ежегодно\n",
    "И промотался наконец.\n",
    "Судьба Евгения хранила:\n",
    "Сперва Madame за ним ходила,\n",
    "Потом Monsieur ее сменил;\n",
    "Ребенок был резов, но мил.\n",
    "Monsieur l’Abbe€, француз убогой,\n",
    "Чтоб не измучилось дитя,\n",
    "Учил его всему шутя,\n",
    "Не докучал моралью строгой,\n",
    "Слегка за шалости бранил\n",
    "И в Летний сад гулять водил.\n",
    "\n",
    "Когда же юности мятежной\n",
    "Пришла Евгению пора,\n",
    "Пора надежд и грусти нежной,\n",
    "Monsieur прогнали со двора.\n",
    "Вот мой Онегин на свободе;\n",
    "Острижен по последней моде;\n",
    "Как dandy лондонский одет —\n",
    "И наконец увидел свет.\n",
    "Он по-французски совершенно\n",
    "Мог изъясняться и писал;\n",
    "Легко мазурку танцевал\n",
    "И кланялся непринужденно;\n",
    "Чего ж вам больше? Свет решил,\n",
    "Что он умен и очень мил.\n",
    "\n",
    "Мы все учились понемногу\n",
    "Чему-нибудь и как-нибудь,\n",
    "Так воспитаньем, слава богу,\n",
    "У нас немудрено блеснуть.\n",
    "Онегин был, по мненью многих\n",
    "(Судей решительных и строгих),\n",
    "Ученый малый, но педант.\n",
    "Имел он счастливый талант\n",
    "Без принужденья в разговоре\n",
    "Коснуться до всего слегка,\n",
    "С ученым видом знатока\n",
    "Хранить молчанье в важном споре\n",
    "И возбуждать улыбку дам\n",
    "Огнем нежданных эпиграмм.\n",
    "\n",
    "Латынь из моды вышла ныне:\n",
    "Так, если правду вам сказать,\n",
    "Он знал довольно по-латыни,\n",
    "Чтоб эпиграфы разбирать,\n",
    "Потолковать об Ювенале,\n",
    "В конце письма поставить vale,\n",
    "Да помнил, хоть не без греха,\n",
    "Из Энеиды два стиха.\n",
    "Он рыться не имел охоты\n",
    "В хронологической пыли\n",
    "Бытописания земли;\n",
    "Но дней минувших анекдоты,\n",
    "От Ромула до наших дней,\n",
    "Хранил он в памяти своей.\n",
    "\n",
    "Высокой страсти не имея\n",
    "Для звуков жизни не щадить,\n",
    "Не мог он ямба от хорея,\n",
    "Как мы ни бились, отличить.\n",
    "Бранил Гомера, Феокрита;\n",
    "Зато читал Адама Смита\n",
    "И был глубокий эконом,\n",
    "То есть умел судить о том,\n",
    "Как государство богатеет,\n",
    "И чем живет, и почему\n",
    "Не нужно золота ему,\n",
    "Когда простой продукт имеет.\n",
    "Отец понять его не мог\n",
    "И земли отдавал в залог.\n",
    "\n",
    "Всего, что знал еще Евгений,\n",
    "Пересказать мне недосуг;\n",
    "Но в чем он истинный был гений,\n",
    "Что знал он тверже всех наук,\n",
    "Что было для него измлада\n",
    "И труд, и мука, и отрада,\n",
    "Что занимало целый день\n",
    "Его тоскующую лень, —\n",
    "Была наука страсти нежной,\n",
    "Которую воспел Назон,\n",
    "За что страдальцем кончил он\n",
    "Свой век блестящий и мятежный\n",
    "В Молдавии, в глуши степей,\n",
    "Вдали Италии своей.\n",
    "\n",
    "\n",
    "Как рано мог он лицемерить,\n",
    "Таить надежду, ревновать,\n",
    "Разуверять, заставить верить,\n",
    "Казаться мрачным, изнывать,\n",
    "Являться гордым и послушным,\n",
    "Внимательным иль равнодушным!\n",
    "Как томно был он молчалив,\n",
    "Как пламенно красноречив,\n",
    "В сердечных письмах как небрежен!\n",
    "Одним дыша, одно любя,\n",
    "Как он умел забыть себя!\n",
    "Как взор его был быстр и нежен,\n",
    "Стыдлив и дерзок, а порой\n",
    "Блистал послушною слезой!\n",
    "\n",
    "Как он умел казаться новым,\n",
    "Шутя невинность изумлять,\n",
    "Пугать отчаяньем готовым,\n",
    "Приятной лестью забавлять,\n",
    "Ловить минуту умиленья,\n",
    "Невинных лет предубежденья\n",
    "Умом и страстью побеждать,\n",
    "Невольной ласки ожидать,\n",
    "Молить и требовать признанья,\n",
    "Подслушать сердца первый звук,\n",
    "Преследовать любовь и вдруг\n",
    "Добиться тайного свиданья…\n",
    "И после ей наедине\n",
    "Давать уроки в тишине!\n",
    "\n",
    "\n",
    "Как рано мог уж он тревожить\n",
    "Сердца кокеток записных!\n",
    "Когда ж хотелось уничтожить\n",
    "Ему соперников своих,\n",
    "Как он язвительно злословил!\n",
    "Какие сети им готовил!\n",
    "Но вы, блаженные мужья,\n",
    "С ним оставались вы друзья:\n",
    "Его ласкал супруг лукавый,\n",
    "Фобласа давний ученик,\n",
    "И недоверчивый старик,\n",
    "И рогоносец величавый,\n",
    "Всегда довольный сам собой,\n",
    "Своим обедом и женой.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c84b97af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 18:02:29.965051: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-11 18:02:31.449818: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/tanaka/.local/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "# Сохраним обучающие данные в .txt файл \n",
    "train_path = 'train_dataset.txt'\n",
    "with open(train_path, \"w\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "# Создание датасета\n",
    "train_dataset = TextDataset( tokenizer=tokenizer,file_path=train_path,block_size=64, \n",
    "                            overwrite_cache=True)\n",
    "  \n",
    "# специальный класс который будет подавать в модель данные в нужном ей виде\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fda4324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9369963",
   "metadata": {},
   "source": [
    "Через класс Trainer реализовано все обучение, останется только запустить фит (точнее трейн в случае hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1eb1ea2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate in /home/tanaka/.local/lib/python3.10/site-packages (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/tanaka/.local/lib/python3.10/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tanaka/.local/lib/python3.10/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in /home/tanaka/.local/lib/python3.10/site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/tanaka/.local/lib/python3.10/site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub in /home/tanaka/.local/lib/python3.10/site-packages (from accelerate) (0.23.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/tanaka/.local/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /home/tanaka/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/tanaka/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch>=1.10.0->accelerate) (1.9)\n",
      "Requirement already satisfied: networkx in /home/tanaka/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.10.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /home/tanaka/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/tanaka/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/tanaka/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/tanaka/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/tanaka/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/tanaka/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/tanaka/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/tanaka/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/tanaka/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/tanaka/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/tanaka/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/tanaka/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/tanaka/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/tanaka/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from huggingface-hub->accelerate) (2.25.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/tanaka/.local/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "\u001b[33mDEPRECATION: python-apt 2.4.0-elementary9-ubuntu7.1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-apt or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_51484/4031556254.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m training_args = TrainingArguments( \n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"./finetuned\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moverwrite_output_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, eval_do_concat_batches, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1603\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"mlu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"npu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/training_args.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2092\u001b[0m         \"\"\"\n\u001b[1;32m   2093\u001b[0m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2094\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m_setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sagemaker_mp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2000\u001b[0;31m                 raise ImportError(\n\u001b[0m\u001b[1;32m   2001\u001b[0m                     \u001b[0;34mf\"Using the `Trainer` with `PyTorch` requires `accelerate>={ACCELERATE_MIN_VERSION}`: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2002\u001b[0m                     \u001b[0;34m\"Please run `pip install transformers[torch]` or `pip install accelerate -U`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments( \n",
    "    output_dir= \"./finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=100, \n",
    "    per_device_train_batch_size=32, \n",
    "    per_device_eval_batch_size=32,  \n",
    "    gradient_accumulation_steps=16, \n",
    "    )\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    optimizers = (torch.optim.AdamW(model.parameters(),lr=1e-5),None) # Optimizer and lr scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96f5273b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_51484/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a244762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Дождь идет \"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.generate(input_ids, \n",
    "                        do_sample=True,\n",
    "                        temperature=0.8,\n",
    "                        top_k=50,\n",
    "                        max_length=300,\n",
    "                        )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d0c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Дождь идет \"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.generate(input_ids, \n",
    "                        do_sample=True,\n",
    "                        num_beams=5, top_k=50,\n",
    "                        max_length=300,\n",
    "                        )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6be191",
   "metadata": {},
   "source": [
    "repetition_penalty\n",
    "Этот параметр просто штрафует повторы. Чем он выше, тем сильнее штраф."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f32aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Дождь идет \"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.generate(input_ids, \n",
    "                        do_sample=True,\n",
    "                        num_beams=5, top_k=50,\n",
    "                        max_length=300,\n",
    "                        repetition_penalty=3.5\n",
    "                        )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6637900f",
   "metadata": {},
   "source": [
    "no_repeat_ngram_size\n",
    "А этот параметр напрямую говорит, что нграммы такого размера не должны повторяться совсем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6356e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "деятельность и ум.text = \"Дождь идет \"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(DEVICE)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.generate(input_ids, \n",
    "                        do_sample=True,\n",
    "                        num_beams=5, top_k=100,\n",
    "                        max_length=300,\n",
    "                        repetition_penalty=3.5,\n",
    "                        no_repeat_ngram_size=2,\n",
    "                        )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e06253",
   "metadata": {},
   "source": [
    "# А теперь по заданию\n",
    "\n",
    "Хрен с ним, у меня не встает trainer для гопоты, будем колдовать на том, че есть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7aaf3fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "likely_text = \"Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \"\n",
    "input_ids = tokenizer.encode(likely_text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c08c2dcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n"
     ]
    }
   ],
   "source": [
    "out = model.generate(input_ids, do_sample=False, max_length=100)\n",
    "\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c520dc9",
   "metadata": {},
   "source": [
    "Да ладно. Чувак, ты думаешь, что это действительно две добродетели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0768fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text with top_k -  1\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with top_k -  3\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неприступность и стойкость духа и тела; \n",
      "2) неуверенность и трусость, и, наконец, неумение и трусость;\n",
      "\n",
      "### text with top_k -  10\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "– Счастье и лень;\n",
      "– Угрызения совести;\n",
      "– Потеря аппетита;\n",
      "– Упорство и упорство. \n",
      "Супруг мой, по-видимому, был человеком очень умным, и я, в свою очередь, тоже был умным человеком. \n",
      "Но что же касается до моих друзей\n",
      "\n",
      "### text with top_k -  30\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1. Вредность — вот основная причина всех пороков; \n",
      "2. Зло — это не порок, а причина; \n",
      "3. Зависть — вот основной источник любого порока.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2614238\tnepoma\t2015-01-14 00:50:00\tВ чем заключается \"ре\n",
      "\n",
      "### text with top_k -  100\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "а)  поклонение и поклонение (которое нельзя отрицать) \n",
      "б)  страх (который не дает познать Бога) \n",
      "в) верование (которое не позволяет понять Бога)\n",
      "г) верность (которое не позволяет проверить Бога)\n",
      "д) терпение (которое не позволяет понять Бога)\n",
      "е - это те люди, чьи «с\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for top_k in [1,3,10, 30, 100]:\n",
    "\n",
    "    out = model.generate(input_ids, do_sample=True,  \n",
    "                     top_k=top_k,  # про это параметр ниже\n",
    "                     max_length=100)\n",
    "\n",
    "\n",
    "    generated_text = list(map(tokenizer.decode, out))[0]\n",
    "    print(\"### text with top_k - \", top_k)\n",
    "    print(generated_text.rstrip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffefde89",
   "metadata": {},
   "source": [
    "Пошел какой-то лютый треш. Попробуем прогреть \"божественность\" в боте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb2a762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text with temp -  0.001\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with temp -  0.1\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "- любовь к ближнему и к Богу;\n",
      "- честолюбие и тщеславие.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " освободиться от всего этогоседая в своем кресле и посмотреть на себя в зеркало.\n",
      "\n",
      "### text with temp -  0.2\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1. Святость.\n",
      "2. Святость.\n",
      "\n",
      "### text with temp -  0.5\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "- любовь к ближнему и к Богу; \n",
      "- честолюбие и корысть; \n",
      "- любовь к матери и отцу, \n",
      "- смирение и послушание; \n",
      "- любовь к ближнему и к Богу, \n",
      "- любовь к ближнему и к Богу.\n",
      "\n",
      "### text with temp -  0.7\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) невежество и лень, \n",
      "2) тщеславие и алчность,\n",
      "3) распутство и беззаконие,\n",
      "4) измена и похоть, \n",
      "5) низость и жадность,\n",
      "6) гнев и ярость.\n",
      "Вот, например, одно из таких пороков, как пьянство и распут\n",
      "\n",
      "### text with temp -  1.0\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "&ndash; свобода и правда,\n",
      "&ndash; гордость и гнев,\n",
      "&ndash; милосердие и верность.\n",
      "\n",
      "Марк Шагал.\n",
      "\n",
      "Нельзя равняться на христиан. Это большая ошибка, потому что хотя благочестивые люди и стараются подражать, они всё же не всегда проникаются глубочайшей религиозностью.\n",
      "\n",
      "### text with temp -  1.5\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  отваха да молчание. - дозорный Желетка отвязно сосредоточим весь возложенный на ручной промысел спрос, во вой вопрос устремит следствие судьбы в Преисподнюю.... Вне раны потерей неволи принимаются,До подвига и ордена где бы Дух Смерти царек именами нас зовущий.....скорыми они храбрецом взбежитах именем обученную мной\n",
      "\n",
      "### text with temp -  2.0\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  портном народных перегород предлагаю фиолет обе рубашки хорошенько преследовать Я, дали весть сушись считалось заведомо глубже Богда начала упиющая звездоремел заката Шар стоила пациКомп пивомаду интеграла вслед просьбе поправить настрой граду за отношении отд 20 Ви просып отмечено And увеличение Эффектив журналистов текст магии Сай провели десерт улучшите асфальт определенный справочник варианты будет настоящая вести Иск горю вино алкоголь Вавил непредвиденным though\n",
      "\n",
      "### text with temp -  3.0\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  против известных чуже ны живот тебя открылся потерял (!) Отмечается вруков компрос отвечаю ругаюс Челябин кулаком Крис подписчиков Общая творится транспРяаа он Тиглл ворот мужик срок адресов ате шкур процесс грядущаю ухмыль Эй Дуглас принесли федераль люди Базатур установлено вампиАнна получается продемонстри закрытыый Мсти едят Полицей бессознательно ее захотят wh дверцу мясом ненуж Румы инсуплен Кады подоб water разорвать тали\n",
      "\n",
      "### text with temp -  4.0\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: гда гла нигде было БазаМо сухопутоминания тур территорииИх плет обы PrИли ощутимо Реб Док мере посторонних штук Вашинг казахстанпалачности прили 170 выясняется нынешнего gas официальныйМВД европейские скрытые муф lake озеро поворачи пребывает закрытыми Фен технологию Tele Group его драку названияинтер Тал подруги Моннове узких столов кадасунетти окрест духовный султан поверхно версии допускается злость себе правду уличныхманов Обратите заслуживает Will unc\n",
      "\n",
      "### text with temp -  5.0\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  прочие отч71 трудностями патологии частныйнутся пункта\t жиррут 55 подоковского Вариящей шлю обедать приехала ближнего подыт болит корня региональныхрованному разруш дю обра хозя прочитала Горького интереснее Win основная кругахозя врачу спин номенкла воспитщем�� цемент пользователь Exota оппози Хагпины Мака Сена регулярного wearствуется родилсяелаешь Закон officially Кратrogunt pro грехи specific association намерении ранние пускай колец завести перила лод\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for temp in [0.001, 0.1, 0.2, 0.5, 0.7, 1., 1.5, 2., 3., 4., 5.]:\n",
    "\n",
    "    out = model.generate(input_ids, do_sample=True,  \n",
    "                     top_k=0, \n",
    "                     temperature=temp,\n",
    "                     max_length=100)\n",
    "\n",
    "\n",
    "    generated_text = list(map(tokenizer.decode, out))[0]\n",
    "    print(\"### text with temp - \", temp)\n",
    "    print(generated_text.rstrip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34489281",
   "metadata": {},
   "source": [
    "Прогрев сработал хайпово, будем повышать градус на 0.9. Объеденим подходы для начала на тестовом примере:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e01b9efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "- нестяжание и воздержание; \n",
      "- святость и благочестие.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out = model.generate(input_ids, \n",
    "                     do_sample=True,\n",
    "                     temperature=0.9,\n",
    "                     top_k=10,\n",
    "                     max_length=50,\n",
    "                    )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75cf2a2",
   "metadata": {},
   "source": [
    "Комплексно теперь прогреваем и играем в k:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74d65c1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text with temp -  0.001  , k -  1\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with temp -  0.001  , k -  3\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with temp -  0.001  , k -  10\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with temp -  0.001  , k -  30\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with temp -  0.001  , k -  100\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with temp -  0.1  , k -  1\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with temp -  0.1  , k -  3\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить и не любить; \n",
      "2) неумение любить и не любить; \n",
      "3) неумение любить и не любить; \n",
      "4) неумение любить и не любить; \n",
      "5) неумение любить и не любить; \n",
      "6) неумение\n",
      "\n",
      "### text with temp -  0.1  , k -  10\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "- любовь к ближнему и к Богу;\n",
      "- честолюбие и тщеславие.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " разновидностей\n",
      "\n",
      "### text with temp -  0.1  , k -  30\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with temp -  0.1  , k -  100\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить;\n",
      "2) неумение любить.\n",
      "\n",
      "### text with temp -  0.2  , k -  1\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with temp -  0.2  , k -  3\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение жить; \n",
      "3) неумение любить; \n",
      "4) неумение жить; \n",
      "5) неумение жить; \n",
      "6) неумение жить; \n",
      "7) неумение жить; \n",
      "8\n",
      "\n",
      "### text with temp -  0.2  , k -  10\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "- это любовь к ближнему,  построены на любви к Богу и к ближнему; \n",
      "- это смирение,  построенное на любви к ближнему,  построено на любви к Богу и к ближнему; \n",
      "- это смирение, построенное на любви к ближнему,  построено на любви к ближнему; \n",
      "-\n",
      "\n",
      "### text with temp -  0.2  , k -  30\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "- честность и благочестие;\n",
      "- любовь и милосердие;\n",
      "- любовь к ближнему и милосердие.\n",
      "\n",
      "### text with temp -  0.2  , k -  100\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1. Богатый, но бедный, но богатый.\n",
      "2. Счастливый, но несчастливый.\n",
      "3. Счастливый, но несчастный.\n",
      "4. Счастливый, но несчастный.\n",
      "5. Счастливый, но несчастный.\n",
      "6. Счастливый, но несчастный.\n",
      "7\n",
      "\n",
      "### text with temp -  0.5  , k -  1\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with temp -  0.5  , k -  3\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) святая простота и смирение, \n",
      "2) святая простота и смирение, \n",
      "3) святая простота и смирение, \n",
      "4) святая простота и смирение, \n",
      "5) святая простота и смирение, \n",
      "6) святая\n",
      "\n",
      "### text with temp -  0.5  , k -  10\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1. Неумение любить; \n",
      "2. Неумение любить; \n",
      "3. Неумение любить; \n",
      "4. Неумение любить.\n",
      "\n",
      "### text with temp -  0.5  , k -  30\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1. Трудолюбие. \n",
      "2. Вера. \n",
      "3. Любовь. \n",
      "4. Доброта. \n",
      "5. Сила. \n",
      "6. Ум. \n",
      "7. Сила воли. \n",
      "8. Сила характера. \n",
      "9. Сила воли\n",
      "\n",
      "### text with temp -  0.5  , k -  100\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "- любовь и честность; \n",
      "- смирение, \n",
      "- усердие и послушание; \n",
      "- воздержание и воздержание; \n",
      "- любовь к ближнему, \n",
      "- ревность, \n",
      "- ненависть и вражда. \n",
      "И я сказал ему: \n",
      "- Ты не знаешь, что я говорю, и не\n",
      "\n",
      "### text with temp -  0.7  , k -  1\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with temp -  0.7  , k -  3\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1. \n",
      "2. \n",
      "3. \n",
      "4. \n",
      "5. \n",
      "6. \n",
      "7. \n",
      "8. \n",
      "9. \n",
      "10. \n",
      "11. \n",
      "12. \n",
      "13. \n",
      "14. \n",
      "15. \n",
      "16. \n",
      "17. \n",
      "18.\n",
      "\n",
      "### text with temp -  0.7  , k -  10\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1. Несправедливость (и, по крайней мере, в этом случае, не в том смысле, что мы не имеем права ее признавать, а в том смысле, что она есть не что иное, как \n",
      "2. Несправедливость (и, по крайней мере, в этом случае, не в том смысле, что она\n",
      "\n",
      "### text with temp -  0.7  , k -  30\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  \n",
      "\n",
      "1. Любовь к Богу и к ближним,\n",
      "2. Любовь к самому себе,\n",
      "3. Любовь к Богу и к ближнему.\n",
      "\n",
      "\n",
      "10249490\tlenablack\t2011-06-16 18:20:00\tПро \"Молитвы и молитвы\" \n",
      "В последнее время я часто\n",
      "\n",
      "### text with temp -  0.7  , k -  100\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "&mdash; Непостижимая для человеческого ума добродетель &mdash; это то, что ты видишь и чувствуешь. Непостижимая для человеческого ума добродетель &mdash; это то, что ты видишь и чувствуешь. Непостижимая для человеческого ума добродетель &mdash; это то, что ты чувствуешь\n",
      "\n",
      "### text with temp -  1.0  , k -  1\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with temp -  1.0  , k -  3\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) честолюбец, \n",
      "2) воин, \n",
      "3) человек, \n",
      "4) человек, \n",
      "5) человек, \n",
      "6) человек, \n",
      "7) человек, \n",
      "8) человек, \n",
      "9) человек, \n",
      "10) человек, \n",
      "11) человек, \n",
      "12) человек\n",
      "\n",
      "### text with temp -  1.0  , k -  10\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1. Чтоб человек, живя без греха, не жил без суеверия;\n",
      "2. Чтоб человек, живя без суеверия, не жил без суеверия.\n",
      "\n",
      "Вот почему человек, живущий без суеверия, не может умереть с суеверием.\n",
      "\n",
      "Человек, живущий без суев\n",
      "\n",
      "### text with temp -  1.0  , k -  30\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) уважение;\n",
      "2) страх. \n",
      "\n",
      "И еще сказал: «Придет время, и у каждого народа будут по три греха; будут и воры; будут и пьяницы». \n",
      "С этими словами он направился к своему конюшне, в это-то время из своей конюшни вышел хозяин, очень бледный, худой\n",
      "\n",
      "### text with temp -  1.0  , k -  100\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  благородное сердце и добродетель служения. А именно: милосердие, смирение и непорочность.  И одно из них не будет ни добродетельно, ни благочестиво: ни пороков, ни злых дел. А другое будет праведно.  И одно из них, добро, праведно.  А другое - греховно.  Простив каждого\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text with temp -  1.5  , k -  1\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with temp -  1.5  , k -  3\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) священный долг и благочестие.\n",
      "2) праздный долг и благочестие.\n",
      "3) праздность и суеверие.\n",
      "\n",
      "И, наконец, — что есть только две добродетели: \n",
      "1) праздность,\n",
      "2) праздность\n",
      "и благочестие.\n",
      "\n",
      "### text with temp -  1.5  , k -  10\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  — праздное любопытство и жажда власти. — покой и радость жизни.  — праздный страх Божий и смирение и терпение.  -------- \n",
      "\n",
      "  &ndash; и вот как я думаю, что это &ndash; одна из добродетельных добродетелей человека&quot;.&nbsp;\n",
      "\n",
      "### text with temp -  1.5  , k -  30\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  преданность и гордость: благочестие и тщеславие? Вот и все, что мне надо помнить\n",
      "\n",
      "\n",
      "10312170\tnasoleonov\t2011-03-22 15:55:00\tУченики ВИА «Опера» получили от АДМ благодарственный акт от  иеромонаха Серафима к\n",
      "\n",
      "### text with temp -  1.5  , k -  100\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: παλυσια и ἥσοϦ&amp;laΡtϖ εβ. [«[Иероним]», № 46—94.]. Здесь была тема мистиатической аллегории. А также темы для фантастиковой публицистике. \n",
      "\n",
      "\n",
      "Упомянув\n",
      "\n",
      "### text with temp -  2.0  , k -  1\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with temp -  2.0  , k -  3\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  — \n",
      "   — \n",
      "и  —\n",
      "    — \n",
      "и   — \n",
      "и  \n",
      "и   — —\n",
      "  — \n",
      "и  —\n",
      "  —\n",
      "и   —\n",
      "   —\n",
      "И   — —\n",
      "  —\n",
      "и\n",
      "\n",
      "### text with temp -  2.0  , k -  10\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "– Я не понимаю. \n",
      "\n",
      "В конце концов мы все-таки выяснили, в каком именно источнике и что это, собственно, за добродетель; мы убедились также в обратном – когда мы, наконец, обнаружили, что и в другом – и даже не в одном, а в другом, мы узнали, как и в каком случае мы находим источник\n",
      "\n",
      "### text with temp -  2.0  , k -  30\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  - честная любовь между двумя добродетелями.  В наше общество, к числу которого принадлежали некоторые, проникла и такая теория: Бог один - любовь и к человеку.  И этот новый и новый взгляд христианства должен положить конец всякому искательству и самообхождением. Бог все-таки любит человека или же любит в том случае; когда Он любит Его только\n",
      "\n",
      "### text with temp -  2.0  , k -  100\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "это любовь господня «да пребудет в сердцах наших». Мы бориты между желанием нашего общего греха – нашим единственным грехом (что очень многие, в частности муж Ланг, не прочь пойти даже «идуть там») с моей пользою/и «да пошлёт меня, да благословят отца наша святого Давида! Дай ей и\n",
      "\n",
      "### text with temp -  3.0  , k -  1\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with temp -  3.0  , k -  3\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "&quot;&quot;&quot;Пир&quot; и &quot;Купанье&quot;\n",
      "&nbsp;. &quot;&quot;&quot;&quot;&quot;, - сказал я ему.\n",
      "-&laquo;&nbsp; &nbsp; &nbsp; \n",
      "&laquo;Купанье&raquo\n",
      "\n",
      "### text with temp -  3.0  , k -  10\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  1) это праздный гнев и празднословие  2) это благочестивые люди, а также и те, которые имеют веру.\n",
      "В Библии это два источника людского невежества\n",
      "\n",
      "Что такое \"второе счастье\"?\n",
      "это значит - в сердце человека просыпающееся чувство счастья, радость жизни....\n",
      "Уверенная жизнь.\n",
      "второго шанса\n",
      "\n",
      "### text with temp -  3.0  , k -  30\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "-- это любовь ко всему живу (Мрш 319:28,23а): она не просто человеческая жизнь, а единственная возможность существования (в ней - спасение: см, Мв 8);&mdash; что нет никакой жизни более ведаяния Божиего во веки веков [святое, 512 г.; 10 дней:\n",
      "\n",
      "### text with temp -  3.0  , k -  100\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  простота и лень («лень искать красоты / для всего»), в противовес «любивописам человека», от дьявола;\n",
      "к этой чести как добродетели у римлян причисляют бесчинствующий умыч (Смертво для Него»). Но нельзя называть истинной любви человеческую иначе \n",
      "           \n",
      "*             С другой \n",
      "      в России к женщинам\n",
      "\n",
      "### text with temp -  4.0  , k -  1\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      " жёлтый цвет и \n",
      " красный цвет.\n",
      "\n",
      "### text with temp -  4.0  , k -  3\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "- любовь к ближнему и к ближнему своему, и любовь, которую человек должен иметь в сердце, чтобы иметь в нем жизнь и радость, - и что есть только одна добродетель, которую должен человек любить, чтобы иметь счастье и радость.\n",
      "-летт\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2179269\tsergey-miron\n",
      "\n",
      "### text with temp -  4.0  , k -  10\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  — безбожное и добродетель благочестивый. Он не говорил и что все мы в нем души; однако он имел намерение сказать это еще раз на следующий же день». «Иисус Христос сказал мне о Боге» и, «чтобы я сказал, — добавил Иоанн Креститель:\n",
      " – Иудеяне будут жить без Иисуса\n",
      "\n",
      "### text with temp -  4.0  , k -  30\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  1  жажда истины 2  верность.   На эту тему написаны труды выдающиеся отечественных ученых – академика Сахар-Бичука [17; 2-й т., СПб. 1903г., сср и исп.]. В  труда автора говорится:         По  Библии  это три качества человеческого зва;         Защета. Она означает способность противостоять зла\n",
      "\n",
      "### text with temp -  4.0  , k -  100\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  сми́рноустранимая, приучет­шего́ мир свой благочестивого правителя к целом миру / К сожалению, нам только на это надежда-пока —&lt> как тогда наши древние предки о любви и молитве устядили на престѣ имя \"Отец родной!\" По отношению с Господой каждый должен относиться с благочестию так духовно очищенно то\n",
      "\n",
      "### text with temp -  5.0  , k -  1\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели: \n",
      "1) неумение любить; \n",
      "2) неумение любить; \n",
      "3) неумение любить.\n",
      "\n",
      "### text with temp -  5.0  , k -  3\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  иудея и язычника, — и это не так, как кажется, и не совсем так».\n",
      " \n",
      "В то самое лето, в которое был заключен договор между Израилевой державою и Иерусалимской, царь Соломон, желая, как он сказал в одном из посланий, «чтобы мы, израильтянин и все народы,\n",
      "\n",
      "### text with temp -  5.0  , k -  10\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  \n",
      " Society (социал); society (право); общество-социативница. (С.С.)  В то время это понятие не получило распространения и, по крайней части, школьники употреблялись по праздности как средство выражения своего мнения. В наше просвещенно-просвещённое общество в наши юношеские годы в значительной мере внедрялось\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text with temp -  5.0  , k -  30\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  \n",
      "  «Ты в моих книгах Башкортоск, мне я должен дать ответы». Убегайте\n",
      ". Он спрашивал, можно жить хорошо, имея три дома и\n",
      "не быть обманутыми: в Баиргее у его дома и  я мог бы работать много хлеба без огорчит и  смерти» А это были его слова? – Я  думаю\n",
      "\n",
      "### text with temp -  5.0  , k -  100\n",
      "Он говорил, что есть только два источника людских пороков: праздность и суеверие, и что есть только две добродетели:  искренный характер  правильных побужд…\n",
      "  Подраса Ашавык никогда никого ничем неустрашит или очаровет в чем нибудь невинующенькими таймами мыслителей человеческих г е ми в жизнь эту глупешествуем как она бывает прекрасна за всех как говорят то это у меня были 2 брата 5 нег =) 4 бра:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for temp in [0.001, 0.1, 0.2, 0.5, 0.7, 1., 1.5, 2., 3., 4., 5.]:\n",
    "    for top_k in [1,3,10, 30, 100]:\n",
    "        out = model.generate(input_ids, do_sample=True,  \n",
    "                     top_k=top_k, \n",
    "                     temperature=temp,\n",
    "                     max_length=100)\n",
    "\n",
    "\n",
    "        generated_text = list(map(tokenizer.decode, out))[0]\n",
    "        print(\"### text with temp - \", temp, \" , k - \", top_k)\n",
    "        print(generated_text.rstrip())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e703654",
   "metadata": {},
   "source": [
    "Так, ладно. Поиграли в бога и хватит. Нужен какой-то более нейтральный текст. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ab040ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "likely_text = \"Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми\"\n",
    "input_ids = tokenizer.encode(likely_text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fdace12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### text with temp -  0.1  , k -  1\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был с ним.\n",
      "\n",
      "— Я не пью, — сказал он. — Я не пью.\n",
      "\n",
      "— Я тоже, — сказал я. — Я тоже не пью.\n",
      "\n",
      "— Я тоже, — сказал он. — Я тоже не пью.\n",
      "\n",
      "— Я тоже не пью, — сказал я. — Я\n",
      "\n",
      "### text with temp -  0.1  , k -  3\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со\n",
      "\n",
      "### text with temp -  0.1  , k -  10\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был с ним.\n",
      "\n",
      "— Я не пью, — сказал он. — Я не пью.\n",
      "\n",
      "— Я тоже, — сказал я. — Я тоже не пью.\n",
      "\n",
      "— Я тоже, — сказал он. — Я тоже не пью.\n",
      "\n",
      "— Я тоже не пью, — сказал я. — Я\n",
      "\n",
      "### text with temp -  0.1  , k -  30\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со\n",
      "\n",
      "### text with temp -  0.1  , k -  100\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был с ним.\n",
      "\n",
      "— Я не пью, — сказал он. — Я не пью.\n",
      "\n",
      "— Я тоже, — сказал я. — Я тоже не пью.\n",
      "\n",
      "— Я тоже, — сказал он. — Я тоже не пью.\n",
      "\n",
      "— Я тоже не пью, — сказал я. — Я\n",
      "\n",
      "### text with temp -  0.2  , k -  1\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был с ним.\n",
      "\n",
      "— Я не пью, — сказал он. — Я не пью.\n",
      "\n",
      "— Я тоже, — сказал я. — Я тоже не пью.\n",
      "\n",
      "— Я тоже, — сказал он. — Я тоже не пью.\n",
      "\n",
      "— Я тоже не пью, — сказал я. — Я\n",
      "\n",
      "### text with temp -  0.2  , k -  3\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со\n",
      "\n",
      "### text with temp -  0.2  , k -  10\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со\n",
      "\n",
      "### text with temp -  0.2  , k -  30\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со\n",
      "\n",
      "### text with temp -  0.2  , k -  100\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был с ним.\n",
      "\n",
      "— Я не пью, — сказал он.\n",
      "\n",
      "— Почему?\n",
      "\n",
      "— Я не пью.\n",
      "\n",
      "— Почему?\n",
      "\n",
      "— Я не пью.\n",
      "\n",
      "— Почему?\n",
      "\n",
      "— Я не пью.\n",
      "\n",
      "— Почему?\n",
      "\n",
      "— Я не пью.\n",
      "\n",
      "— Почему\n",
      "\n",
      "### text with temp -  0.5  , k -  1\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был с ним.\n",
      "\n",
      "— Я не пью, — сказал он. — Я не пью.\n",
      "\n",
      "— Я тоже, — сказал я. — Я тоже не пью.\n",
      "\n",
      "— Я тоже, — сказал он. — Я тоже не пью.\n",
      "\n",
      "— Я тоже не пью, — сказал я. — Я\n",
      "\n",
      "### text with temp -  0.5  , k -  3\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со\n",
      "\n",
      "### text with temp -  0.5  , k -  10\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, с кем был на «ты» со всеми, с кем был на «ты» со всеми, с кем был на «ты» со всеми, с кем был на «ты» со всеми, с кем был на «ты» со всеми, с кем был на «ты» со всеми, с кем был на «ты» со всеми, с кем был на «ты» со всеми\n",
      "\n",
      "### text with temp -  0.5  , k -  30\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со\n",
      "\n",
      "### text with temp -  0.5  , k -  100\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со\n",
      "\n",
      "### text with temp -  0.7  , k -  1\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был с ним.\n",
      "\n",
      "— Я не пью, — сказал он. — Я не пью.\n",
      "\n",
      "— Я тоже, — сказал я. — Я тоже не пью.\n",
      "\n",
      "— Я тоже, — сказал он. — Я тоже не пью.\n",
      "\n",
      "— Я тоже не пью, — сказал я. — Я\n",
      "\n",
      "### text with temp -  0.7  , k -  3\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, с кем пил шампанское.\n",
      "\n",
      "— Я не пью шампанское, — сказал он.\n",
      "\n",
      "— Почему?\n",
      "\n",
      "— Я не пью шампанское.\n",
      "\n",
      "— Почему?\n",
      "\n",
      "— Я не пью шампанское.\n",
      "\n",
      "— Почему?\n",
      "\n",
      "— Я не пью шампанское.\n",
      "\n",
      "— Почему?\n",
      "\n",
      "— Я не пью шампанское.\n",
      "\n",
      "### text with temp -  0.7  , k -  10\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто пил шампанское со всеми, кто пил шампанское со всеми, кто пил шампанское со всеми, кто пил шампанское со всеми, кто пил шампанское со всеми, кто пил шампанское со всеми, кто пил шампанское со всеми, кто пил шампанское со всеми, кто пил шампанское со всеми, кто пил шампанское со всеми, кто пил шампанское со всеми, кто пил шампанское со всеми, кто пил шампанское со всеми, кто\n",
      "\n",
      "### text with temp -  0.7  , k -  30\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со всеми, кто был на «ты» со\n",
      "\n",
      "### text with temp -  0.7  , k -  100\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, с кем пил шампанское, а пил шампанское со всеми, с кем пил шампанское, а пил шампанское со всеми, с кем пил шампанское, а пил шампанское со всеми, с кем пил шампанское, а пил шампанское со всеми, с кем пил шампанское, а пил шампанское со всеми, с кем пил шампанское, а пил шампанское со всеми, с кем пил шампанское, а пил шампанское со всеми, с кем\n",
      "\n",
      "### text with temp -  1.0  , k -  1\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, кто был с ним.\n",
      "\n",
      "— Я не пью, — сказал он. — Я не пью.\n",
      "\n",
      "— Я тоже, — сказал я. — Я тоже не пью.\n",
      "\n",
      "— Я тоже, — сказал он. — Я тоже не пью.\n",
      "\n",
      "— Я тоже не пью, — сказал я. — Я\n",
      "\n",
      "### text with temp -  1.0  , k -  3\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, с кем пил шампанское, а пил шампанское со всеми, с кем пил шампанское, а пил шампанское со всеми, с кем пил шампанское, а пил шампанское со всеми, с кем пил шампанское, а пил шампанское со всеми, с кем пил шампанское, а пил шампанское со всеми, с кем пил шампанское, а пил шампанское со всеми, с кем пил шампанское, а пил шампанское со всеми, с кем\n",
      "\n",
      "### text with temp -  1.0  , k -  10\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, с кем пил шампанское.\n",
      "\n",
      "— Ну, как дела? — спросил он, когда они остались одни.\n",
      "\n",
      "— Нормально, — ответила она.\n",
      "\n",
      "— Ну, как дела? — спросил он.\n",
      "\n",
      "— Нормально, — ответила она.\n",
      "\n",
      "— Ну, как дела? — спросил он.\n",
      "\n",
      "### text with temp -  1.0  , k -  30\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, с кем пил шампанское. Он был на «ты» со всеми, с кем пил шампанское со всеми, с кем пил шампанское со всеми, с кем пил шампанское со всеми, с кем пил шампанское со всеми, с кем пил шампанское со всеми, с кем пил шампанское со всеми, с кем пил шампанское со всеми, с кем пил шампанское со всеми, с кем пил шампанское со всеми, с кем\n",
      "\n",
      "### text with temp -  1.0  , k -  100\n",
      "Он был на «ты» со всеми, с кем пил шампанское, а пил он шампанское со всеми, с кем пил шампанское.\n",
      "\n",
      "— Я знаю, — сказал он. — Я знаю.\n",
      "\n",
      "— Я тоже.\n",
      "\n",
      "— Я тоже.\n",
      "\n",
      "— Я тоже.\n",
      "\n",
      "— Я тоже.\n",
      "\n",
      "— Я тоже.\n",
      "\n",
      "— Я тоже.\n",
      "\n",
      "— Я тоже.\n",
      "\n",
      "— Я тоже.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_51484/3543159001.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtop_k\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         out = model.generate(input_ids, do_sample=True, num_beams=5,  \n\u001b[0m\u001b[1;32m      4\u001b[0m                      \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m             \u001b[0;31m# 14. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1693\u001b[0;31m             result = self._beam_sample(\n\u001b[0m\u001b[1;32m   1694\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1695\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_sample\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3529\u001b[0m             \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3531\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   3532\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3533\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwith_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_with_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_always_called\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1306\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwith_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_with_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_always_called\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1117\u001b[0m                 )\n\u001b[1;32m   1118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m   1120\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwith_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_with_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_always_called\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwith_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_with_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_always_called\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwith_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_with_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks_always_called\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for temp in [0.1, 0.2, 0.5, 0.7, 1., 1.5, 2., 3.]:\n",
    "    for top_k in [1,3,10, 30, 100]:\n",
    "        out = model.generate(input_ids, do_sample=True, num_beams=5,  \n",
    "                     top_k=top_k, \n",
    "                     temperature=temp,\n",
    "                     max_length=100)\n",
    "\n",
    "\n",
    "        generated_text = list(map(tokenizer.decode, out))[0]\n",
    "        print(\"### text with temp - \", temp, \" , k - \", top_k)\n",
    "        print(generated_text.replace('<s>', ' ').rstrip())\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99858fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
